{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import redditutils as ru\n",
    "import word2vecReader as wvr\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README                     word2vecReaderUtils.py\r\n",
      "\u001b[34m__pycache__\u001b[m\u001b[m                word2vec_twitter_model.bin\r\n",
      "word2vecReader.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls word2vec_twitter_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('cleaned_shower.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['quality'] = df['score'].apply(lambda x: ru.make_labels(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3927000364998175"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.quality.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['title'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['title']\n",
    "y = df['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_short = X_train[:100000]\n",
    "y_train_short = y_train[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_shorter = X_train[:5000]\n",
    "y_train_shorter = y_train[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_shorter = X_test[:2500]\n",
    "y_test_shorter = y_test[:2500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word embedding with word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./word2vec_twitter_model.bin\"\n",
    "model = KeyedVectors.load_word2vec_format(model_path, binary=True, unicode_errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_features(words, model, num_features):\n",
    "    features = np.zeros(num_features)\n",
    "    \n",
    "    model_vocab = set(model.index2word)\n",
    "    \n",
    "    num_words = 0\n",
    "    \n",
    "    # Loop over words in documents. If the word is in model's vocabulary,\n",
    "    # generate its feature vector\n",
    "    for w in words:\n",
    "        if w in model_vocab:\n",
    "            num_words += 1\n",
    "            features = np.add(features, model[w])\n",
    "            \n",
    "    # Normalize the feature vector\n",
    "    features = np.divide(features, num_words)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_vecs(docs, model, num_features):\n",
    "    # Get the average feature vector for each showerthought based on the words it's comprised of\n",
    "    counter = 0\n",
    "    \n",
    "    doc_vector = np.zeros((len(docs), num_features))\n",
    "    \n",
    "    for d in docs:\n",
    "        if counter%100 == 0:\n",
    "            print(f'Finished document number {counter}')\n",
    "            \n",
    "        # Add this document's feature vector to doc_vector\n",
    "        doc_vector[counter] = make_features(d, model, num_features)\n",
    "            \n",
    "        counter += 1\n",
    "    return doc_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished document number 0\n",
      "Finished document number 100\n",
      "Finished document number 200\n",
      "Finished document number 300\n",
      "Finished document number 400\n",
      "Finished document number 500\n",
      "Finished document number 600\n",
      "Finished document number 700\n",
      "Finished document number 800\n",
      "Finished document number 900\n",
      "Finished document number 1000\n",
      "Finished document number 1100\n",
      "Finished document number 1200\n",
      "Finished document number 1300\n",
      "Finished document number 1400\n",
      "Finished document number 1500\n",
      "Finished document number 1600\n",
      "Finished document number 1700\n",
      "Finished document number 1800\n",
      "Finished document number 1900\n",
      "Finished document number 2000\n",
      "Finished document number 2100\n",
      "Finished document number 2200\n",
      "Finished document number 2300\n",
      "Finished document number 2400\n"
     ]
    }
   ],
   "source": [
    "features_test = document_vecs(X_test_shorter, model, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.04595001,  0.11741913,  0.02367049, ..., -0.05944299,\n",
       "         0.0996727 ,  0.1051121 ],\n",
       "       [-0.05437983,  0.06098557,  0.00839084, ..., -0.09163244,\n",
       "         0.12625733,  0.12745151],\n",
       "       [-0.06536687,  0.04458294,  0.03854551, ..., -0.10071999,\n",
       "         0.11806172,  0.18819486],\n",
       "       ...,\n",
       "       [ 0.01586874,  0.08002475,  0.03917049, ..., -0.06246087,\n",
       "         0.10881239,  0.21049194],\n",
       "       [-0.02163505,  0.00665951, -0.01421123, ..., -0.13325126,\n",
       "         0.13243245,  0.2009986 ],\n",
       "       [ 0.00686216,  0.06225939, -0.04909481, ..., -0.00733361,\n",
       "         0.11381253,  0.14644653]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished document number 0\n",
      "Finished document number 100\n",
      "Finished document number 200\n",
      "Finished document number 300\n",
      "Finished document number 400\n",
      "Finished document number 500\n",
      "Finished document number 600\n",
      "Finished document number 700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in true_divide\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished document number 800\n",
      "Finished document number 900\n",
      "Finished document number 1000\n",
      "Finished document number 1100\n",
      "Finished document number 1200\n",
      "Finished document number 1300\n",
      "Finished document number 1400\n",
      "Finished document number 1500\n",
      "Finished document number 1600\n",
      "Finished document number 1700\n",
      "Finished document number 1800\n",
      "Finished document number 1900\n",
      "Finished document number 2000\n",
      "Finished document number 2100\n",
      "Finished document number 2200\n",
      "Finished document number 2300\n",
      "Finished document number 2400\n",
      "Finished document number 2500\n",
      "Finished document number 2600\n",
      "Finished document number 2700\n",
      "Finished document number 2800\n",
      "Finished document number 2900\n",
      "Finished document number 3000\n",
      "Finished document number 3100\n",
      "Finished document number 3200\n",
      "Finished document number 3300\n",
      "Finished document number 3400\n",
      "Finished document number 3500\n",
      "Finished document number 3600\n",
      "Finished document number 3700\n",
      "Finished document number 3800\n",
      "Finished document number 3900\n",
      "Finished document number 4000\n",
      "Finished document number 4100\n",
      "Finished document number 4200\n",
      "Finished document number 4300\n",
      "Finished document number 4400\n",
      "Finished document number 4500\n",
      "Finished document number 4600\n",
      "Finished document number 4700\n",
      "Finished document number 4800\n",
      "Finished document number 4900\n"
     ]
    }
   ],
   "source": [
    "features_train = document_vecs(X_train_shorter, model, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 400)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Throw it in to a Random Forest\n",
    "\n",
    "Cluster if this doesn't work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.12027476,  0.09294142,  0.0002563 , ..., -0.0215239 ,\n",
       "         0.11527485,  0.11532648],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train[739]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train[3705]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1999200"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_train[~np.isnan(features_train)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_dropna = features_train[~np.isnan(features_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train_shorter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_dropna = np.delete(features_train, [739, 3705], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_shorter = np.array(y_train_shorter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_shorter = np.delete(y_train_shorter, [739, 3705])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 739,  739,  739,  739,  739,  739,  739,  739,  739,  739,  739,\n",
       "         739,  739,  739,  739,  739,  739,  739,  739,  739,  739,  739,\n",
       "         739,  739,  739,  739,  739,  739,  739,  739,  739,  739,  739,\n",
       "         739,  739,  739,  739,  739,  739,  739,  739,  739,  739,  739,\n",
       "         739,  739,  739,  739,  739,  739,  739,  739,  739,  739,  739,\n",
       "         739,  739,  739,  739,  739,  739,  739,  739,  739,  739,  739,\n",
       "         739,  739,  739,  739,  739,  739,  739,  739,  739,  739,  739,\n",
       "         739,  739,  739,  739,  739,  739,  739,  739,  739,  739,  739,\n",
       "         739,  739,  739,  739,  739,  739,  739,  739,  739,  739,  739,\n",
       "         739,  739,  739,  739,  739,  739,  739,  739,  739,  739,  739,\n",
       "         739,  739,  739,  739,  739,  739,  739,  739,  739,  739,  739,\n",
       "         739,  739,  739,  739,  739,  739,  739,  739,  739,  739,  739,\n",
       "         739,  739,  739,  739,  739,  739,  739,  739,  739,  739,  739,\n",
       "         739,  739,  739,  739,  739,  739,  739,  739,  739,  739,  739,\n",
       "         739,  739,  739,  739,  739,  739,  739,  739,  739,  739,  739,\n",
       "         739,  739,  739,  739,  739,  739,  739,  739,  739,  739,  739,\n",
       "         739,  739,  739,  739,  739,  739,  739,  739,  739,  739,  739,\n",
       "         739,  739,  739,  739,  739,  739,  739,  739,  739,  739,  739,\n",
       "         739,  739,  739,  739,  739,  739,  739,  739,  739,  739,  739,\n",
       "         739,  739,  739,  739,  739,  739,  739,  739,  739,  739,  739,\n",
       "         739,  739,  739,  739,  739,  739,  739,  739,  739,  739,  739,\n",
       "         739,  739,  739,  739,  739,  739,  739,  739,  739,  739,  739,\n",
       "         739,  739,  739,  739,  739,  739,  739,  739,  739,  739,  739,\n",
       "         739,  739,  739,  739,  739,  739,  739,  739,  739,  739,  739,\n",
       "         739,  739,  739,  739,  739,  739,  739,  739,  739,  739,  739,\n",
       "         739,  739,  739,  739,  739,  739,  739,  739,  739,  739,  739,\n",
       "         739,  739,  739,  739,  739,  739,  739,  739,  739,  739,  739,\n",
       "         739,  739,  739,  739,  739,  739,  739,  739,  739,  739,  739,\n",
       "         739,  739,  739,  739,  739,  739,  739,  739,  739,  739,  739,\n",
       "         739,  739,  739,  739,  739,  739,  739,  739,  739,  739,  739,\n",
       "         739,  739,  739,  739,  739,  739,  739,  739,  739,  739,  739,\n",
       "         739,  739,  739,  739,  739,  739,  739,  739,  739,  739,  739,\n",
       "         739,  739,  739,  739,  739,  739,  739,  739,  739,  739,  739,\n",
       "         739,  739,  739,  739,  739,  739,  739,  739,  739,  739,  739,\n",
       "         739,  739,  739,  739,  739,  739,  739,  739,  739,  739,  739,\n",
       "         739,  739,  739,  739,  739,  739,  739,  739,  739,  739,  739,\n",
       "         739,  739,  739,  739, 3705, 3705, 3705, 3705, 3705, 3705, 3705,\n",
       "        3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705,\n",
       "        3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705,\n",
       "        3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705,\n",
       "        3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705,\n",
       "        3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705,\n",
       "        3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705,\n",
       "        3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705,\n",
       "        3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705,\n",
       "        3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705,\n",
       "        3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705,\n",
       "        3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705,\n",
       "        3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705,\n",
       "        3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705,\n",
       "        3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705,\n",
       "        3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705,\n",
       "        3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705,\n",
       "        3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705,\n",
       "        3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705,\n",
       "        3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705,\n",
       "        3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705,\n",
       "        3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705,\n",
       "        3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705,\n",
       "        3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705,\n",
       "        3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705,\n",
       "        3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705,\n",
       "        3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705,\n",
       "        3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705,\n",
       "        3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705,\n",
       "        3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705,\n",
       "        3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705,\n",
       "        3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705,\n",
       "        3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705,\n",
       "        3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705,\n",
       "        3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705,\n",
       "        3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705,\n",
       "        3705, 3705, 3705, 3705, 3705, 3705, 3705, 3705]),\n",
       " array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "         13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "         26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "         39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "         52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "         65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "         91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "        104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "        117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "        130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "        143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "        169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "        195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
       "        208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
       "        221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
       "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
       "        247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
       "        260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
       "        273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
       "        286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
       "        299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
       "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
       "        325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
       "        338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
       "        351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
       "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376,\n",
       "        377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389,\n",
       "        390, 391, 392, 393, 394, 395, 396, 397, 398, 399,   0,   1,   2,\n",
       "          3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,  15,\n",
       "         16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,\n",
       "         29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
       "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
       "         55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,\n",
       "         68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,\n",
       "         81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,\n",
       "         94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106,\n",
       "        107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
       "        120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132,\n",
       "        133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,\n",
       "        146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
       "        159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
       "        172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184,\n",
       "        185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
       "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n",
       "        211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
       "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236,\n",
       "        237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249,\n",
       "        250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262,\n",
       "        263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275,\n",
       "        276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288,\n",
       "        289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301,\n",
       "        302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314,\n",
       "        315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327,\n",
       "        328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340,\n",
       "        341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
       "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366,\n",
       "        367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379,\n",
       "        380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392,\n",
       "        393, 394, 395, 396, 397, 398, 399]))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.isnan(features_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 400)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.55728854 0.56422569 0.56816817]\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "\n",
    "score = cross_val_score(rfc, features_train_dropna, y_train_shorter, cv=3)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definitely some improvement with word2vec! ~.56 ROC AUC!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans()\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "pipe = make_pipeline(km, rfc)\n",
    "\n",
    "tuning_params = {'randomforestclassifier__n_estimators': [50, 100, 150, 200],\n",
    "                 'Kmeans__n_clusters': [i for i in range(1, 20)]}\n",
    "\n",
    "bs = BayesSearchCV(pipe, tuning_params, cv=3, scoring='roc_auc')\n",
    "\n",
    "bs.fit(features, y_train_shorter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
