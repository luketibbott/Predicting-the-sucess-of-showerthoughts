{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import redditutils\n",
    "import pickle\n",
    "\n",
    "\n",
    "from string import punctuation\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import words\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import SnowballStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from scipy.io import mmwrite, mmread\n",
    "\n",
    "from gensim import corpora, models, similarities, matutils\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppress Pandas' automatic conversion of utc column to scientific notation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('showerthoughts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.392702"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df.score > 1]) / len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "39% of submissions get more than one upvote. This makes \"greater than one upvote\" a good candidate for our criteria for a good post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Data columns (total 9 columns):\n",
      "author          1000000 non-null object\n",
      "title           1000000 non-null object\n",
      "subreddit       1000000 non-null object\n",
      "score           1000000 non-null int64\n",
      "num_comments    1000000 non-null int64\n",
      "retrieved_on    1000000 non-null int64\n",
      "id              1000000 non-null object\n",
      "created_utc     1000000 non-null int64\n",
      "selftext        591622 non-null object\n",
      "dtypes: int64(4), object(5)\n",
      "memory usage: 68.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['created_utc'] = pd.to_datetime(df['created_utc'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>retrieved_on</th>\n",
       "      <th>id</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>selftext</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>os_coxae</td>\n",
       "      <td>everyone that's ever said \"i'm speechless\" is a goddamn liar.</td>\n",
       "      <td>Showerthoughts</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1466445837</td>\n",
       "      <td>4ixl2n</td>\n",
       "      <td>2016-05-11 22:38:48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Calrizle</td>\n",
       "      <td>i wonder how many people i've talked to who have been doing kaigles during our conversation.</td>\n",
       "      <td>Showerthoughts</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1466494743</td>\n",
       "      <td>4lfjxn</td>\n",
       "      <td>2016-05-28 12:03:56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[deleted]</td>\n",
       "      <td>\"palindrome\" is a let down as a word. rhinoplasty sure isn't.</td>\n",
       "      <td>Showerthoughts</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1466493929</td>\n",
       "      <td>4ldt85</td>\n",
       "      <td>2016-05-28 01:21:03</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[deleted]</td>\n",
       "      <td>when you tell someone to keep a secret, it is no longer a secret</td>\n",
       "      <td>Showerthoughts</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1466423373</td>\n",
       "      <td>4hmcbg</td>\n",
       "      <td>2016-05-03 08:30:35</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[deleted]</td>\n",
       "      <td>someone had the the time to create the words, \"dick\", \"penis\", and \"vagina\"</td>\n",
       "      <td>Showerthoughts</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1466474842</td>\n",
       "      <td>4k9ngz</td>\n",
       "      <td>2016-05-20 18:29:28</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      author  \\\n",
       "0   os_coxae   \n",
       "1   Calrizle   \n",
       "2  [deleted]   \n",
       "3  [deleted]   \n",
       "4  [deleted]   \n",
       "\n",
       "                                                                                          title  \\\n",
       "0                                 everyone that's ever said \"i'm speechless\" is a goddamn liar.   \n",
       "1  i wonder how many people i've talked to who have been doing kaigles during our conversation.   \n",
       "2                                 \"palindrome\" is a let down as a word. rhinoplasty sure isn't.   \n",
       "3                              when you tell someone to keep a secret, it is no longer a secret   \n",
       "4                   someone had the the time to create the words, \"dick\", \"penis\", and \"vagina\"   \n",
       "\n",
       "        subreddit  score  num_comments  retrieved_on      id  \\\n",
       "0  Showerthoughts      0             0    1466445837  4ixl2n   \n",
       "1  Showerthoughts      0             0    1466494743  4lfjxn   \n",
       "2  Showerthoughts      0             0    1466493929  4ldt85   \n",
       "3  Showerthoughts      0             0    1466423373  4hmcbg   \n",
       "4  Showerthoughts      0             0    1466474842  4k9ngz   \n",
       "\n",
       "          created_utc   selftext  quality  \n",
       "0 2016-05-11 22:38:48        NaN        0  \n",
       "1 2016-05-28 12:03:56        NaN        0  \n",
       "2 2016-05-28 01:21:03  [deleted]        0  \n",
       "3 2016-05-03 08:30:35  [deleted]        0  \n",
       "4 2016-05-20 18:29:28  [deleted]        0  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>retrieved_on</th>\n",
       "      <th>id</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>selftext</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>990321</th>\n",
       "      <td>Jolkro</td>\n",
       "      <td>tattoos and babies have the same tabu. no one says they are ugly to their owners, but you can be sure the ugliness is talked about to everyone else.</td>\n",
       "      <td>Showerthoughts</td>\n",
       "      <td>1077</td>\n",
       "      <td>49</td>\n",
       "      <td>1536660067</td>\n",
       "      <td>91qs2i</td>\n",
       "      <td>2018-07-25 10:51:13</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        author  \\\n",
       "990321  Jolkro   \n",
       "\n",
       "                                                                                                                                                       title  \\\n",
       "990321  tattoos and babies have the same tabu. no one says they are ugly to their owners, but you can be sure the ugliness is talked about to everyone else.   \n",
       "\n",
       "             subreddit  score  num_comments  retrieved_on      id  \\\n",
       "990321  Showerthoughts   1077            49    1536660067  91qs2i   \n",
       "\n",
       "               created_utc   selftext  quality  \n",
       "990321 2018-07-25 10:51:13  [removed]        1  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation_prime = punctuation.replace('\\'', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuation_prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_punc(s):\n",
    "    return ''.join(c for c in s if c not in punctuation_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['quality'] = df['score'].apply(lambda x: redditutils.make_labels(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['title', 'created_utc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.iloc[:int(len(df)*.70), :]\n",
    "test = df.iloc[int(len(df)*.70):, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = df[['title', 'created_utc']]\n",
    "resp = df['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(feat, resp, stratify = resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_short_train = X_train.iloc[:int(len(X_train)*.1), :]\n",
    "X_short_test = X_test.iloc[:int(len(X_test)*.1), :]\n",
    "\n",
    "y_short_train = y_train[:int(len(y_train)*.1)]\n",
    "y_short_test = y_test[:int(len(y_test)*.1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000, 2)"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_short_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word count vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "# English words\n",
    "words_corpus = set(words.words())\n",
    "# Stop words\n",
    "stop = set(stopwords.words('english'))\n",
    "# English words minus stop words\n",
    "acceptable_words = words_corpus - stop\n",
    "analyzer = CountVectorizer().build_analyzer()\n",
    "stem = SnowballStemmer('english')\n",
    "\n",
    "def english_corpus(doc, stemmer=stem):\n",
    "    return [stemmer.stem(w) for w in analyzer(doc) if w in acceptable_words]\n",
    "\n",
    "cv = CountVectorizer(stop_words='english', min_df = 2, max_df = .95, analyzer=english_corpus,\n",
    "                     strip_accents='unicode', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_short_train_dtm = cv.fit_transform(X_short_train['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_short_test_dtm = cv.transform(X_short_test['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(cv, open('fitted_cv.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn implementation of LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_sk = LatentDirichletAllocation(n_components = 10, learning_method='online', learning_decay = 0.6,\n",
    "                                   learning_offset = 1024, topic_word_prior = .056)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.6,\n",
       "             learning_method='online', learning_offset=1024,\n",
       "             max_doc_update_iter=100, max_iter=10, mean_change_tol=0.001,\n",
       "             n_components=10, n_jobs=None, n_topics=None, perp_tol=0.1,\n",
       "             random_state=None, topic_word_prior=0.056,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_sk.fit(X_short_train_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(lda_sk, open('fitted_lda_short.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_train_features = lda_sk.transform(X_short_train_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_test_features = lda_sk.transform(X_short_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmwrite('short_train_matrix.csv', X_short_train_dtm)\n",
    "mmwrite('short_test_matrix.csv', X_short_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2236.0784312037654"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_sk.perplexity(X_short_train_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOPIC 0\n",
      "way\n",
      "first\n",
      "say\n",
      "peopl\n",
      "come\n",
      "like\n",
      "someon\n",
      "name\n",
      "use\n",
      "alway\n",
      "\n",
      "TOPIC 1\n",
      "world\n",
      "realli\n",
      "see\n",
      "could\n",
      "life\n",
      "never\n",
      "human\n",
      "would\n",
      "futur\n",
      "peopl\n",
      "\n",
      "TOPIC 2\n",
      "post\n",
      "made\n",
      "read\n",
      "word\n",
      "find\n",
      "tell\n",
      "anyon\n",
      "next\n",
      "hear\n",
      "toilet\n",
      "\n",
      "TOPIC 3\n",
      "good\n",
      "everi\n",
      "bad\n",
      "die\n",
      "phone\n",
      "school\n",
      "liter\n",
      "high\n",
      "realli\n",
      "star\n",
      "\n",
      "TOPIC 4\n",
      "new\n",
      "instead\n",
      "long\n",
      "like\n",
      "movi\n",
      "music\n",
      "man\n",
      "idea\n",
      "countri\n",
      "origin\n",
      "\n",
      "TOPIC 5\n",
      "time\n",
      "like\n",
      "day\n",
      "one\n",
      "would\n",
      "us\n",
      "peopl\n",
      "go\n",
      "trump\n",
      "still\n",
      "\n",
      "TOPIC 6\n",
      "much\n",
      "water\n",
      "car\n",
      "food\n",
      "seen\n",
      "noth\n",
      "sleep\n",
      "never\n",
      "pretti\n",
      "imagin\n",
      "\n",
      "TOPIC 7\n",
      "differ\n",
      "earth\n",
      "mean\n",
      "would\n",
      "realiz\n",
      "sound\n",
      "one\n",
      "complet\n",
      "top\n",
      "media\n",
      "\n",
      "TOPIC 8\n",
      "get\n",
      "peopl\n",
      "like\n",
      "wonder\n",
      "mani\n",
      "look\n",
      "take\n",
      "feel\n",
      "year\n",
      "shower\n",
      "\n",
      "TOPIC 9\n",
      "make\n",
      "someth\n",
      "would\n",
      "live\n",
      "thing\n",
      "becom\n",
      "ever\n",
      "call\n",
      "someon\n",
      "best\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for topic in range(10):\n",
    "    print(f\"TOPIC {topic}\")\n",
    "    for j in np.argsort(-lda_sk.components_, axis=1)[topic,:10]:\n",
    "        print(cv.get_feature_names()[j])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.58950989, 0.5953642 , 0.5933468 ])"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(rfc, X_short_train_cv, y_short_train, cv=3, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MVP = ~.59 AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.51727064, 0.51928188, 0.51481831])"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "\n",
    "cross_val_score(nb, X_short_train_cv.toarray(), y_short_train, cv=3, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier()\n",
    "\n",
    "cross_val_score(xgb, X_short_train_cv.toarray(), y_short_train, cv=2, scoring='roc_auc', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-420-b513f4ac7292>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpipe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mmake_pipeline\u001b[0;34m(*steps, **kwargs)\u001b[0m\n\u001b[1;32m    592\u001b[0m         raise TypeError('Unknown keyword arguments: \"{}\"'\n\u001b[1;32m    593\u001b[0m                         .format(list(kwargs.keys())[0]))\n\u001b[0;32m--> 594\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_name_estimators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, steps, memory)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_steps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_validate_steps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_steps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;31m# validate names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 0)"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(cv, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
